#!/usr/bin/env python

from __future__ import division
import numpy as np
import pandas as pd
# TODO figure out what the hold up is on importing this, with the prints
import multi_tracker_analysis as mta
# TODO delete me
print 'mta=', mta.__file__
import glob
from os.path import join, split
import os
import re
import pickle
from stimuli.srv import LoadSequenceRequest
import sys
# TODO maybe remove this dependency if it means it cant be run easily on windows?
import rosparam

# TODO will this work w/ python2?
# seems to, but may be unnecessary
from collections import OrderedDict
# TODO replace rosparam usage w/ this?
# using this rather than pyyaml, because this supports rejecting duplicate keys
from ruamel import yaml
from ruamel.yaml.comments import CommentedSeq

import string

# see falsetru's answer at
# https://stackoverflow.com/questions/21872366/plural-string-formatting
class PluralFormatter(string.Formatter):
    def get_value(self, key, args, kwargs):
        if isinstance(key, int) or isinstance(key, long):
            return args[key]

        if key in kwargs:
            return kwargs[key]

        if '(' in key and key.endswith(')'):
            key, rest = key.split('(', 1)

            try:
                idx = int(key)
                value = args[idx]
            except ValueError:
                value = kwargs[key]

            suffix = rest.rstrip(')').split(',')
            if len(suffix) == 1:
                # TODO what is this for?
                suffix.insert(0, '')
            return suffix[0] if value <= 1 else suffix[1]
        else:
            raise KeyError(key)

# TODO use config file for these flags / command line args

# TODO check current dir -> check for env var -> check that dir
# what all indications of having data from this kind of experiment?
# not sure i want to make config file mandatory

verbose = False

# TODO flag to just show interactive plot?

only_show_interactive = False
show_plots = False
save_plots = True
plot_format = 'png'
make_plots = show_plots or save_plots
sort_traces_by = 'decision_bias'

# TODO it seems these were originally for displaying?
# separate flags for whether the text should be added to traces plot?
want_time_spent = True
want_decision_bias = True
# TODO turn off interactive plots if this is false? rename interactive flag?
display_metrics = want_time_spent or want_decision_bias 

# TODO also include option to color lines in metric change plots by same labels?
show_experiment_labels = True

print_version = True

if make_plots:
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    import seaborn as sns
    #from matplotlib import rcParams
    #rcParams.update({'figure.autolayout': True})
    # was it set_style?
    sns.set_style('white')

# TODO load
left_shock = 6
right_shock = 5

def load_metadata(d):
    files = glob.glob(join(d, '*_stimuli.p'))
    if len(files) > 1:
        raise IOError('too many stimulus files in ' + d)
    elif len(files) < 1:
        raise IOError('found no stimulus files in ' + d)
    filename = files[0]
    with open(filename, 'rb') as f:
        # TODO it seems like pins2odors would really be more useful?
        odors2left_pins, odors2right_pins, _, trial_structure = pickle.load(f)
    times = dict()
    times['start'] = trial_structure[0].to_sec()
    times['end'] = trial_structure[-1].to_sec()
    stimuli = filter(lambda x: type(x) is LoadSequenceRequest, trial_structure)
    times['pretest_start'] = stimuli[0].seq.start.to_sec()
    times['posttest_start'] = stimuli[-1].seq.start.to_sec()
    times['test_duration'] = stimuli[0].seq.end.to_sec() - stimuli[0].seq.start.to_sec()

    # TODO load
    left_pins = [56, 57, 59]
    right_pins = [54, 55, 61]

    # TODO check
    def pin_from(check, group):
        pins = [p for p in check if p in group]
        assert len(pins) == 1
        return pins[0]

    def odor_for_pin(odors2pins, pin):
        odors = [o for o, p in odors2pins.items() if p == pin]
        assert len(odors) == 1
        return odors[0]

    def prepost_odors(odors2pins, pin_group, stimuli):
        prepins = stimuli[0].seq.pins
        postpins = stimuli[-1].seq.pins
        prepin = pin_from(prepins, pin_group)
        postpin = pin_from(postpins, pin_group)
        return odor_for_pin(odors2pins, prepin), odor_for_pin(odors2pins, postpin)

    pretest_left_odor, posttest_left_odor = prepost_odors(odors2left_pins, left_pins, stimuli)
    pretest_right_odor, posttest_right_odor = prepost_odors(odors2right_pins, right_pins, stimuli)

    # TODO check that all blocks would yield the same answer
    for block in stimuli[1:-1]:
        odors = []
        if left_shock in block.seq.pins:
            odors += [o for o, p in odors2left_pins.items() if p in block.seq.pins]
        if right_shock in block.seq.pins:
            odors += [o for o, p in odors2right_pins.items() if p in block.seq.pins]
        # TODO check
        odors = set(odors)
        if len(odors) > 0:
            assert len(odors) == 1
            reinforced_odor = odors.pop()
            break

    metadata = dict()
    metadata['times'] = times
    metadata['pretest_left_odor'] = pretest_left_odor
    metadata['posttest_left_odor'] = posttest_left_odor
    metadata['pretest_right_odor'] = pretest_right_odor
    metadata['posttest_right_odor'] = posttest_right_odor
    # TODO check
    metadata['reinforced_odor'] = reinforced_odor
    '''
    if split(d)[-1] == '20170919_090747':
        print ''
        print 'trial_structure', trial_structure
        print 'experiment:', split(d)[-1]
        print 'odors2left_pins:', odors2left_pins
        print 'odors2right_pins:', odors2right_pins
        print 'pretest left:', odors2left_pins[pretest_left_odor], pretest_left_odor 
        print 'posttest left:', odors2left_pins[posttest_left_odor], posttest_left_odor 
        print 'pretest right:', odors2right_pins[pretest_right_odor], pretest_right_odor 
        print 'posttest right:', odors2right_pins[posttest_right_odor], posttest_right_odor 
        print 'reinforced odor', reinforced_odor
        print ''
        print ''
    '''
    metadata['stimuli'] = list(stimuli)
    # TODO switch to new style
    left_pins2odors = dict((v, k) for k, v in odors2left_pins.items())
    right_pins2odors = dict((v, k) for k, v in odors2right_pins.items())

    assert len(left_pins2odors) == len(odors2left_pins), 'some odors map to multiple left pins'
    assert len(right_pins2odors) == len(odors2right_pins), 'some odors map to multiple right pins'

    # TODO check
    for p in left_pins2odors.keys():
        assert not p in right_pins2odors.keys(), 'pin ' + str(p) + \
            ' was listed as both left and right'
    for p in right_pins2odors.keys():
        assert not p in left_pins2odors.keys(), 'pin ' + str(p) + \
            ' was listed as both left and right'

    metadata['left_pins2odors'] = left_pins2odors
    metadata['right_pins2odors'] = right_pins2odors
    metadata['odors'] = set(odors2left_pins.keys()) | set(odors2right_pins.keys())
    return metadata

# TODO refactor so nothing is called on import?

# TODO allow script to be run in directory w/ data
path = os.path.expanduser('~/data/retracked')
# TODO just walk from path in future?

dirs = [join(path, d) for d in os.listdir(path) if re.match(r'([0-9]){8}_([0-9]){6}', d) \
    and os.path.isdir(join(path, d))]

# TODO maybe have a flag to save figures for rejects?
curr_fly = 0
fly2data = dict()
fly2meta = dict()
all_odors = set()

experiment2label = dict()
curr_char = ord('A')

# TODO do most processing while loading, to not need as much memory?
for d in map(lambda x: join(path, x), dirs):
    if not os.path.isdir(d):
        continue

    # TODO check trial structure times against those in log
    common_metadata = load_metadata(d)
    for o in common_metadata['odors']:
        all_odors.add(o)

    # TODO can join take a variable # of args?
    for f in glob.glob(join(d, '*.hdf5')):
        metadata = dict(common_metadata)
        # TODO make it so this generates the (optional) config? notify if doing so
        # TODO TODO exclude trajectories that don't cover enough ground
        data, _ = mta.read_hdf5_file_to_pandas.load_and_preprocess_data(f)
        '''
        print 'position_x range', data['position_x'].min(), data['position_x'].max()
        print 'position_y range', data['position_y'].min(), data['position_y'].max()
        '''
        match = re.search('_N([0-9])_', f)
        # TODO why is it more than what is in the parens?
        #print 'MATCH', match
        metadata['n'] = int(match.group(0)[2:-1])

        stamp = split(d)[-1]
        fly2data[curr_fly] = data
        metadata['dir'] = d

        if d not in experiment2label:
            experiment2label[d] = chr(curr_char)
            curr_char += 1

        # TODO also load from compressor_rois_..., if this is missing
        # or just figure out why it was missing?
        roi_points = rosparam.load_file(join(d, 'roi_N' + str(metadata['n']) + \
            '.yaml'))[0][0]['roi_points']
        metadata['roi_points'] = roi_points
        fly2meta[curr_fly] = metadata
        curr_fly += 1

if make_plots:
    # TODO seed or something for better colors w/ # odors=2
    cmap = sns.color_palette('husl', len(all_odors))
    odor2color = dict()
    for o, c in zip(all_odors, cmap):
        odor2color[o] = c

yaml_filename = join(path, 'analysis_rejects.yaml')
yaml_loader = yaml.YAML()

if os.path.exists(yaml_filename):
    with open(yaml_filename, 'r') as f:
        yaml_loader.allow_duplicate_keys = False
        rejects = yaml_loader.load(f)
        if rejects is None:
            rejects = OrderedDict()

else:
    rejects = OrderedDict()

# organize better?
zero_before_test_by = 60
# TODO why did 1100 not work? isn't sequence 1000 long?
crop_to_seconds = 1300

def plot_trace(cropped_rel_times, position_y, meta, metrics=None, y_max_min=None, ax=None):
    label_set = set()
    labels = []
    handles = []

    start = meta['times']['pretest_start'] - zero_before_test_by

    # calculate percent time in each odor region
    # TODO make one variable at top which controls which dimension to use as long axis
    # and have this (and elsewhere) depend on that
    y_vals = map(lambda p: p[1], meta['roi_points'])
    y_mid = np.mean(y_vals)

    if ax is None:
        plt.plot(cropped_rel_times , (-1) * (position_y - y_mid), \
            c='black', linewidth=1.3)
    else:
        ax.plot(cropped_rel_times , (-1) * (position_y - y_mid), \
            c='black', linewidth=1.3)

    plt.xlabel('Seconds')

    y_max = max(map(lambda x: x[1], meta['roi_points']))
    y_min = min(map(lambda x: x[1], meta['roi_points']))
    if verbose:
        print 'y_max', y_max, 'y_min', y_min, 'using y midline', y_mid

    # TODO TODO filter out trajectories that don't move much. 
    # just use floris' config file thing?

    if y_max_min is None:
        centered_y_vals = map(lambda y: y - y_mid, y_vals)
        y_max_above_mid = max(centered_y_vals)
        y_min_below_mid = min(centered_y_vals)

    else:
        y_max_above_mid, y_min_below_mid = y_max_min

    y_shock_to_odor = 2
    y_beyond_arena = 0
    small_height = 4
    odor_patch_alpha = 0.4
    shock_patch_alpha = 0.8
    shock_color = 'red'

    large_height = (y_max_above_mid - y_min_below_mid) / 2 + y_beyond_arena

    plotting_y_max = None
    plotting_y_min = None
    plotting_x_max = None
    plotting_x_min = None
    
    for i, s in enumerate(meta['stimuli']):
        width = (s.seq.end - s.seq.start).to_sec()
        for p in s.seq.pins:
            color = 'b'
            label = None
            if p is left_shock:
                label = 'shock'
                color = shock_color
                height = small_height
                y0 = y_min_below_mid - y_beyond_arena - (y_shock_to_odor + small_height)
                alpha = shock_patch_alpha

            elif p is right_shock:
                label = 'shock'
                color = shock_color
                height = small_height
                y0 = y_max_above_mid + y_beyond_arena + y_shock_to_odor
                alpha = shock_patch_alpha

            # TODO i think the reason these have been displaying correctly is that
            # y_min_below_mid ~= y_max_above_mid, though those are probably still
            # calculated for the wrong sides. fix? use one number equal to their average?

            # displayed on down side in plot, and down should also be left in the video
            # , with closer arenas further to the right
            elif p in meta['left_pins2odors']:
                #print 'left odor', meta['left_pins2odors'][p]
                label = meta['left_pins2odors'][p]
                color = odor2color[label]
                y0 = y_min_below_mid - y_beyond_arena
                height = large_height
                alpha = odor_patch_alpha

            # displayed on top sides of plots, which should also be right in the video
            elif p in meta['right_pins2odors']:
                #print 'right odor', meta['right_pins2odors'][p]
                label = meta['right_pins2odors'][p]
                color = odor2color[label]
                # because we define the middle as the new origin
                y0 = 0
                height = large_height
                alpha = odor_patch_alpha

            else:
                #print 'skipping pin', p
                continue

            # TODO maybe subdivide for shocks? (to reflect actual pulse cycle ~2.5s on/off)
            x0 = s.seq.start.to_sec() - start
            #print 'seq.start.to_sec()', s.seq.start.to_sec(), 'x0', x0, 'width', width
            if i == 0:
                # define acceptable mismatch here?
                if x0 <= 0.0:
                    if verbose:
                        print 'WARNING! seems no video was recorded for first ' + \
                            str(-x0) + ' seconds of first block (pre-training test)'

            else:
                assert x0 > 0, 'times we want to disply should not be negative. was ' + str(x0)

            assert x0 + width < crop_to_seconds, 'last time index of patched ' + \
                'region should fall within limits of cropped experiment. was ' + \
                str(x0 + width) + ' end=' + str(crop_to_seconds)
            #print 'patching pin', p, 'from', (x0, y0), 'with w=', width, 'and h=', height

            p = patches.Rectangle((x0, y0), width, height, alpha=alpha, \
                facecolor=color, edgecolor=color)

            if ax is None:
                ax = plt.gca()
            ax.add_patch(p)

            if (not label is None)  and (not label in label_set):
                label_set.add(label)
                labels.append(label)
                handles.append(p)

            curr_y_max = y0 + height
            if plotting_y_max is None or plotting_y_max < curr_y_max:
                plotting_y_max = curr_y_max

            curr_y_min = y0
            if plotting_y_min is None or plotting_y_min > curr_y_min:
                plotting_y_min = curr_y_min

            curr_x_max = x0 + width
            if plotting_x_max is None or plotting_x_max < curr_x_max:
                plotting_x_max = curr_x_max

            curr_x_min = x0
            if plotting_x_min is None or plotting_x_min > curr_x_min:
                plotting_x_min = curr_x_min

    if display_metrics and not metrics is None:
        # TODO other metrics?
        y_pos = 0.77
        x_0 = 0.99
        dx = 0.08
        fontsize = 7
        valign = 'top'
        # TODO crop a little tighter and move x_pos to the left?
        if want_time_spent:
            text = ''
            # TODO make robust to fly #0 getting skipped
            if fly == 0:
                text += 'pre: %.3f in reinforced\npost: %.3f in reinforced' % \
                    (metrics['fraction_reinforced_pre'], metrics['fraction_reinforced_post'])
            else:
                text += 'pre: %.3f\npost: %.3f' % \
                    (metrics['fraction_reinforced_pre'], metrics['fraction_reinforced_post'])

            # TODO scale fontsize w/ # of traces?
            ax.text(x_0, y_pos, text, transform=ax.transAxes, fontsize=fontsize, \
                verticalalignment=valign)

        if want_decision_bias:
            #if fly == 0:
            text = '%.3f\n%.3f' % \
                (metrics['decision_bias_pre'], metrics['decision_bias_post'])

            x_pos = x_0 if not want_time_spent else (x_0 + dx)
            ax.text(x_pos, y_pos, text, transform=ax.transAxes, fontsize=fontsize, \
                verticalalignment=valign)

        # TODO was preference / performance (?) index distinct from the above?

        # no sure i want a box?
        # TODO what does verticalalignment do?

    # different name for this flag?
    if show_experiment_labels:
        ax.text(-.04, 0.6, experiment2label[meta['dir']], \
            transform=ax.transAxes, fontsize=12, verticalalignment='top')

    return plotting_x_min, plotting_x_max, plotting_y_min, plotting_y_max, labels, handles


key2group = {'1': 'good',
             '2': 'never_active',
             '3': 'inactive_after_shock',
             '4': 'no_sample_either_test',
             '5': 'no_receive_shock',
             '6': 'no_fly',
             '7': 'tracker_artifacts',
             '8': 'suspicious'}

def press(event):
    # TODO rank these according to how common they are?
    if event.key in key2group:
        group = key2group[event.key]

        # TODO fix this printing. not displaying.
        print group, '            \r',
        press.group = group
        press.fig.canvas.mpl_disconnect(press.cid)
        #print 'closing fig'
        plt.close(press.fig)

new_keys = False
# open yaml for writing
# TODO fix patching / plot ranges
for fly, data in fly2data.items():
    meta = fly2meta[fly]
    stamp = split(meta['dir'])[-1]

    already_labelled = False
    # try to find the current fly in one of the dictionaries for any group in the
    # analysis_rejects.yaml file. if it is in one, no need to get a label for it here.
    for reason, reject_dict in rejects.items():
        if (not reject_dict is None) and stamp in reject_dict \
            and meta['n'] in reject_dict[stamp]:

            # TODO use actual yaml filename?
            if verbose:
                print stamp, meta['n'], 'was already labeled in analysis_rejects.yaml'

            already_labelled = True
            break

    if already_labelled:
        continue
    elif verbose:
        print stamp, meta['n'], 'was NOT in yaml'

    if not new_keys:
        print 'Keys to label traces:'
        for k in sorted(key2group.keys()):
            print k, '-', key2group[k]
        
    new_keys = True
    curr_times = (data['time_epoch_secs'] + data['time_epoch_nsecs'] / 1e9).as_matrix()
    nonzero_times = curr_times.nonzero()[0]

    if nonzero_times.size == 0:
        if not 'no_fly' in rejects:
            rejects['no_fly'] = OrderedDict()

        if not stamp in rejects['no_fly']:
            rejects['no_fly'][stamp] = []

        rejects['no_fly'][stamp].append(meta['n'])
        continue

    fig = plt.figure()
    cid = fig.canvas.mpl_connect('key_press_event', press)

    # TODO factor out? (repeated below)
    start = meta['times']['pretest_start'] - zero_before_test_by
    cropped_indices = (curr_times - start) <= crop_to_seconds
    cropped_times = curr_times[cropped_indices]
    # relative to start of experiment
    cropped_rel_times = cropped_times - start

    #plot_trace(curr_times, data['position_y'], meta, ax=ax)
    # TODO why did this seem to be on a log x scale once?
    plot_trace(cropped_rel_times, data['position_y'][cropped_indices], meta)

    press.fig = fig
    press.cid = cid

    while True:
        try:
            # TODO maybe just delay before / after?
            plt.show()
            break
        except AttributeError:
            # TODO what to do? need to fail?
            print 'caught attribute error'
            pass

    if not hasattr(press, 'group'):
        sys.exit()

    if not press.group in rejects:
        rejects[press.group] = OrderedDict()

    if not stamp in rejects[press.group]:
        rejects[press.group][stamp] = []

    rejects[press.group][stamp].append(meta['n'])

if new_keys:
    print ''

if new_keys:
    for reason in rejects:
        for stamp in rejects[reason]:
            # TODO problems roundtripping this?
            rejects[reason][stamp] = CommentedSeq(sorted(list(rejects[reason][stamp])))
            # TODO current api? still necessary?
            rejects[reason][stamp].fa.set_flow_style()

    print 'saving to', yaml_filename
    with open(yaml_filename, 'w') as f:
        # TODO does roundtripdumper work w/o using roundtriploader?
        # (should) necessary though?
        yaml.dump(rejects, f, Dumper=yaml.RoundTripDumper)

bad = dict()
for reason, reject_dict in rejects.items():
    if reason == 'good' or reject_dict is None:
        continue

    if reason == 'suspicious' and (not reject_dict is None):
        # TODO print which
        print 'WARNING: using some trajectories marked as suspicious for analysis.'
        continue

    for exp_id, rois in reject_dict.items():
        if exp_id in bad:
            bad[exp_id] = bad[exp_id] | set(rois)
        else:
            bad[exp_id] = set(rois)


def fraction_time_reinforced(cropped_times, y_positions, meta, prefix):
    """
    """
    assert prefix == 'pre' or prefix == 'post'

    # TODO maybe compute these in another function, and pass indexed
    # times and y_positions to all metric functions?

    # TODO maybe use times from log, rather than these?
    test_indices = np.logical_and(cropped_times > meta['times'][prefix + 'test_start'], \
        cropped_times < (meta['times'][prefix + 'test_start'] + \
        meta['times']['test_duration']))

    assert test_indices.dtype == np.bool, \
        'later operations assume indices represented as boolean mask'

    # TODO try not to recalculate?
    y_vals = map(lambda p: p[1], meta['roi_points'])
    y_mid = np.mean(y_vals)
    left = y_positions > y_mid

    # TODO include a buffer region that is called in neither direction 
    # to make this more robust to misspecifying the middle of the arena?
    # TODO check uniform sampling rate? otherwise it is fraction of indices...
    fraction_left = np.sum(left[test_indices]) / np.sum(test_indices)
    #print 'sum ' + prefix + 'test indices on left', np.sum(left[test_indices])
    #print 'sum ' + prefix + 'test_indices', np.sum(test_indices)
    if meta['reinforced_odor'] == meta[prefix + 'test_left_odor']:
        fraction_reinforced = fraction_left
        if verbose:
            print(prefix + 'test_left_odor was reinforced')
        nonshocked_odor = meta[prefix + 'test_right_odor']

    elif meta['reinforced_odor'] == meta[prefix + 'test_right_odor']:
        fraction_reinforced = 1 - fraction_left
        if verbose:
            print(prefix + 'test_left_odor was NOT reinforced')
        nonshocked_odor = meta[prefix + 'test_left_odor']

    else:
        assert False, 'neither of ' + prefix + 'test_<left/right>_odor(s) were equal to reinforced odor'
    assert meta['reinforced_odor'] != nonshocked_odor

    return fraction_reinforced, test_indices, nonshocked_odor


def decision_bias(cropped_times, y_positions, meta, prefix, \
    mean_y_pixels, choice_zone_width_mm=5):
    """
    should be signed, unlike that in Parnas, with positive indicating a bias against
    shocked odor.
    """
    assert prefix == 'pre' or prefix == 'post'

    test_indices = np.logical_and(cropped_times > meta['times'][prefix + 'test_start'], \
        cropped_times < (meta['times'][prefix + 'test_start'] + \
        meta['times']['test_duration']))
    assert test_indices.dtype == np.bool, \
        'later operations assume indices represented as boolean mask'

    y_vals = map(lambda p: p[1], meta['roi_points'])
    y_mid = np.mean(y_vals)

    # TODO use ratio of this height in pixels to mean height in pixels to
    # get more accurate est of real boundaries of decision zone?
    # probably assumes camera is properly calibrated?
    mean_selected_height_mm = 51
    # assumes properly calibrated camera (or negligible geometric distortion)
    choice_zone_pixels = (choice_zone_width_mm / mean_selected_height_mm) * mean_y_pixels
    # TODO check left / right here is correct. maybe orientation settable via parameter?
    left_border = y_mid - (choice_zone_pixels / 2)
    right_border = y_mid + (choice_zone_pixels / 2)

    y_positions_in_test = y_positions[test_indices]
    # just need to count all exits from choice zone, separately for each side
    in_choice_zone = np.logical_and(y_positions_in_test >= left_border, \
        y_positions_in_test <= right_border).astype(np.int8)

    # diff is -1 at the end of a run of Trues (1s)
    # TODO debounce at all? filter trajectories better first?
    exits = np.argwhere(np.diff(in_choice_zone) == -1)
    towards_left = 0
    towards_right = 0
    for e in exits:
        if abs(y_positions_in_test[e] - left_border) < abs(y_positions_in_test[e] - right_border):
            towards_left += 1
        else:
            towards_right += 1

    total_decisions = towards_left + towards_right
    # TODO put behind verbose flag after done debugging
    if verbose:
        print 'decisions toward left', towards_left
        print 'decisions toward right', towards_right

    if total_decisions == 0:
        # TODO does this propagate appropriately
        bias_against_left = np.nan

    else:
        # TODO TODO is this right?
        bias_against_left = (towards_left - towards_right) / total_decisions

    # convention is negative = aversion to shocked odor, 
    # positive = attraction to shocked odor
    # so that changes are in same direction as fraction of time spent in reinforced
    if meta['reinforced_odor'] == meta[prefix + 'test_left_odor']:
        bias_against_reinforced = (-1) * bias_against_left
        if verbose:
            print(prefix + 'test_left_odor was reinforced')
        nonshocked_odor = meta[prefix + 'test_right_odor']

    elif meta['reinforced_odor'] == meta[prefix + 'test_right_odor']:
        bias_against_reinforced = bias_against_left
        if verbose:
            print(prefix + 'test_left_odor was NOT reinforced')
        nonshocked_odor = meta[prefix + 'test_left_odor']

    else:
        assert False, 'neither of ' + prefix + 'test_<left/right>_odor(s) were equal to reinforced odor'
    assert meta['reinforced_odor'] != nonshocked_odor

    return bias_against_reinforced, test_indices, nonshocked_odor


def plot_metric_change(metric_pre, metric_post, title='', ylabel='', fly2meta=None, \
    fly_nums_in_order=None, exps=None, rois=None, filename=None, allow_negative=False):
    """
    """
    group1 = [fly2meta, fly_nums_in_order]
    group2 = [exps, rois]
    is_none = lambda x: x is None
    def check_all_or_none(group):
        elements_none = map(is_none, group)
        if any(elements_none):
            assert all(elements_none), 'either all parameters within group' + \
                ' must be set, or none should be'
            return False
        return True

    use_group1 = check_all_or_none(group1)
    use_group2 = check_all_or_none(group2)
    assert use_group1 ^ use_group2, 'parameter groups were not exclusive'

    # TODO option for adding these plots to subplots? pass in ax?
    fig = plt.figure(figsize=(4,4))
    plt.title(title)
    plt.ylabel(ylabel)
    x = [0, 1]
    plt.xticks(x, ['Pre', 'Post'])
    ax = plt.gca()
    ax.set_xlim([-.2, 1.2])

    if allow_negative:
        ax.set_ylim([-1.1, 1.1])
    else:
        ax.set_ylim([-.1, 1.1])

    if use_group1:
        for fly, pre, post in zip(fly_nums_in_order, metric_pre, metric_post):
            label = split(fly2meta[fly]['dir'])[-1] + ', ROI ' + str(fly2meta[fly]['n'])
            ax.plot(x, [pre, post], marker='.', label=label, color='black')

    elif use_group2:
        for exp, roi, pre, post in zip(exps, rois, metric_pre, metric_post):
            label = split(exp)[-1] + ', ROI ' + str(roi)
            ax.plot(x, [pre, post], marker='.', label=label, color='black')

    # TODO boxplot on top of this?
    if save_plots:
        assert not filename is None, 'must pass filename to plot_metric_change' + \
            ' if save_plots is True'
        # TODO save at same level as all experiment directories?
        fig.savefig(filename, bbox_inches='tight')

    if show_plots:
        def on_plot_hover(ax, event):
            on_any_curve = False
            for curve in ax.get_lines():
                if curve.contains(event)[0]:
                    on_any_curve = True
                    # drawing at one side would probably also be acceptable
                    # rectangular patch as relief, behind text?
                    if not hasattr(on_plot_hover, 'text_handle'):
                        on_plot_hover.text_handle = ax.text(float(event.xdata), \
                                float(event.ydata), curve.get_label())

                    else:
                        on_plot_hover.text_handle.set_x(float(event.xdata))
                        on_plot_hover.text_handle.set_y(float(event.ydata))
                        on_plot_hover.text_handle.set_text(curve.get_label())
                    on_plot_hover.text_handle.set_visible(True)

            if (not on_any_curve) and hasattr(on_plot_hover, 'text_handle'):
                on_plot_hover.text_handle.set_visible(False)

            ax.figure.canvas.draw_idle()

        fig.canvas.mpl_connect('motion_notify_event', lambda e: on_plot_hover(ax, e)) 
        plt.show()

    else:
        plt.close('all')


def analyze_group(fly2data, title=''):
    """
    """
    y_maxes_above_mid = []
    y_mins_below_mid = []
    y_ranges = []

    # TODO assert that we are analyzing with dimension that corresponds to long axis of roi

    for m in fly2meta.values():
        y_vals = map(lambda p: p[1], m['roi_points'])
        curr_mid = np.mean(y_vals)
        centered_y_vals = map(lambda y: y - curr_mid, y_vals)
        y_maxes_above_mid.append(max(centered_y_vals))
        y_mins_below_mid.append(min(centered_y_vals))
        y_ranges.append(max(y_vals) - min(y_vals))

    # TODO might want to just determine plotting range from these
    y_max_above_mid = max(y_maxes_above_mid)
    y_min_below_mid = min(y_mins_below_mid)
    mean_y_pixels = np.mean(y_ranges)
    
    if verbose:
        print 'mean y pixels:', mean_y_pixels
        print 'y_min_below_mid', y_min_below_mid, 'y_max_above_mid', y_max_above_mid

    # TODO divide into mch and oct? make a dataframe including all variables (like side, etc)?
    fractions_reinforced_pre = []
    fractions_reinforced_post = []
    decision_biases_pre = []
    decision_biases_post = []

    # TODO line up images of ROIs, with drawn midline, to check for those errors
    # TODO label / group by the reinforced odor?

    plotting_y_max = None
    plotting_y_min = None
    plotting_x_max = None
    plotting_x_min = None

    axes_to_set_limits = []
    fly_nums_in_order = []

    if make_plots:
        scale = 12
        fig, axes = plt.subplots(nrows=len(fly2data), sharex=True, sharey=True, \
            squeeze=True, figsize=(scale * 1, scale * 1))
        if not type(axes) is np.ndarray:
            axes = [axes]

    dfs = []
    for_plotting = []
    curr_idx = 0

    for fly, data in fly2data.items():
        meta = fly2meta[fly]
        # TODO what happens to missing data?
        # plotted as zero? not plotted?
        curr_times = (data['time_epoch_secs'] + data['time_epoch_nsecs'] / 1e9).as_matrix()

        # TODO so does floris initialize something to 5000? blocks written in that size?
        #print(curr_times.shape)
        nonzero_times = curr_times.nonzero()[0]
        if nonzero_times.size == 0:
            # TODO automatically add these to yaml? recommend?
            # count earlier to get the right # of subplots?
            if verbose:
                print 'SKIPPING FLY', meta['n'], 'FROM', meta['dir']
            continue

        if verbose:
            print 'experiment', split(meta['dir'])[-1], \
                '({})'.format(experiment2label[meta['dir']]), 'fly', meta['n']

        start = meta['times']['pretest_start'] - zero_before_test_by

        # TODO print how much this fly has walked (in each test period?)

        #print 'START TIME =', start
        #print '# of zero entries', curr_times.size - nonzero_times.size

        # because for some of these, the tracking ran much longer than the stimulus presentation
        cropped_indices = (curr_times - start) <= crop_to_seconds
        cropped_times = curr_times[cropped_indices]

        if want_time_spent:
            fraction_reinforced_pre, pretest_indices, nonshocked_odor = \
                fraction_time_reinforced(cropped_times, data['position_y'][cropped_indices], \
                meta, 'pre')
            fraction_reinforced_post, posttest_indices, _ = \
                fraction_time_reinforced(cropped_times, data['position_y'][cropped_indices], \
                meta, 'post')

            if verbose:
                print 'fraction time spent in reinforced pre:', fraction_reinforced_pre
                print 'fraction time spent in reinforced post:', fraction_reinforced_post

        if want_decision_bias:
            decision_bias_pre, _, _ = decision_bias(cropped_times, \
                data['position_y'][cropped_indices].as_matrix(), meta, 'pre', mean_y_pixels)
            decision_bias_post, _, _ = decision_bias(cropped_times, \
                data['position_y'][cropped_indices].as_matrix(), meta, 'post', mean_y_pixels)

            if verbose:
                print 'decision bias pre:', decision_bias_pre
                print 'decision bias post:', decision_bias_post
                print ''
 
        assert not np.any(np.logical_and(pretest_indices, posttest_indices)), \
            'pre and post test indices overlapped'

        n_pretest_indices = np.sum(pretest_indices)
        n_posttest_indices = np.sum(posttest_indices)
        curr_rel_err = abs(n_pretest_indices - n_posttest_indices) / n_posttest_indices
        '''
        rel_indices_tol = 0.35
        assert curr_rel_err <= rel_indices_tol, '# pretest_indices=' + \
            str(n_pretest_indices) + ', # posttest_indices=' + str(n_posttest_indices) + \
            ', relative error=' + str(curr_rel_err)
        '''
        if curr_rel_err != 0:
            if verbose:
                print 'WARNING! relative difference in timepoints in pre and post test = ' + \
                    str(curr_rel_err)

        fractions_reinforced_pre.append(fraction_reinforced_pre)
        fractions_reinforced_post.append(fraction_reinforced_post)
        decision_biases_pre.append(decision_bias_pre)
        decision_biases_post.append(decision_bias_post)

        # TODO convert odor + conc to good string representation
        curr_df = pd.DataFrame({'experiment': meta['dir'], \
                      'roi': meta['n'], \
                      'shocked_odor': meta['reinforced_odor'][0], \
                      'nonshocked_odor': nonshocked_odor[0], \
                      'decision_bias_pre': decision_bias_pre, \
                      'decision_bias_post': decision_bias_post, \
                      'fraction_reinforced_pre': fraction_reinforced_pre, \
                      'fraction_reinforced_post': fraction_reinforced_post}, index=[curr_idx])
        dfs.append(curr_df)

        # TODO only print metrics if not make_plots and display_metrics? just latter?
        if make_plots:
            # TODO TODO filter very high frequency noise out before plotting
            # multiplied by negative one so it is displayed in same orientation as video
            # and also by patches (rectangles) indicating which side each odor is on
            # TODO maybe try antialiased=True/False? default?
            # rasterized default?
            ax = axes[curr_idx]
            
            metrics = dict()
            if want_time_spent:
                metrics['fraction_reinforced_pre'] = fraction_reinforced_pre
                metrics['fraction_reinforced_post'] = fraction_reinforced_post

            if want_decision_bias:
                metrics['decision_bias_pre'] = decision_bias_pre
                metrics['decision_bias_post'] = decision_bias_post

            # relative to start of experiment
            cropped_rel_times = cropped_times - start
            if sort_traces_by is None:
                curr_x_min, curr_x_max, curr_y_min, curr_y_max, labels, handles = \
                    plot_trace(cropped_rel_times, data['position_y'][cropped_indices], \
                    meta, metrics=metrics, y_max_min=(y_max_above_mid, y_min_below_mid), ax=ax)

                if plotting_y_max is None or plotting_y_max < curr_y_max:
                    plotting_y_max = curr_y_max

                if plotting_y_min is None or plotting_y_min > curr_y_min:
                    plotting_y_min = curr_y_min

                if plotting_x_max is None or plotting_x_max < curr_x_max:
                    plotting_x_max = curr_x_max

                if plotting_x_min is None or plotting_x_min > curr_x_min:
                    plotting_x_min = curr_x_min

                axes_to_set_limits.append(ax)

            else:
                # TODO factor stuff around to avoid this mess?
                args_to_plot = (cropped_rel_times, data['position_y'][cropped_indices], \
                    meta)
                # will need to fill in the ax later. this is to change order of subplots.
                kwargs_to_plot = {'metrics': metrics, 'y_max_min': (y_max_above_mid, \
                    y_min_below_mid)}
                # TODO will redefining these variables change the values already in the list?
                # probably not?
                for_plotting.append((args_to_plot, kwargs_to_plot))
            fly_nums_in_order.append(fly)
        # TODO just use enumerate instead?
        curr_idx += 1

    # TODO ignore_index?
    df = pd.concat(dfs)

    # sort by change in metric and plot subplots in that order
    if sort_traces_by == 'decision_bias':
        sort_on = df['decision_bias_pre'] - df['decision_bias_post']

    elif sort_traces_by == 'time_spent':
        sort_on = df['fraction_reinforced_pre'] - df['fraction_reinforced_post']

    if not sort_traces_by is None:
        plotting_order = np.argsort(sort_on)
        for i, si in enumerate(plotting_order):
            ax = axes[i]
            args_to_plot, kwargs_to_plot = for_plotting[si]
            curr_x_min, curr_x_max, curr_y_min, curr_y_max, labels, handles = \
                plot_trace(*args_to_plot, ax=ax, **kwargs_to_plot)

            if plotting_y_max is None or plotting_y_max < curr_y_max:
                plotting_y_max = curr_y_max

            if plotting_y_min is None or plotting_y_min > curr_y_min:
                plotting_y_min = curr_y_min

            if plotting_x_max is None or plotting_x_max < curr_x_max:
                plotting_x_max = curr_x_max

            if plotting_x_min is None or plotting_x_min > curr_x_min:
                plotting_x_min = curr_x_min

            axes_to_set_limits.append(ax)

    if make_plots:
        # TODO take union of labels & handles returned above?
        fig.legend(handles=handles, labels=labels, loc='lower left', fontsize=9)

    if verbose:
        print 'plotting ranges: x', (plotting_x_min, plotting_x_max), 'y', \
            (plotting_y_min, plotting_y_max)

    # TODO do this for single plots within plot_trace?
    # relative
    y_bord = 0.025
    x_bord = 0.025
    x_range = plotting_x_max - plotting_y_min
    y_range = plotting_y_max - plotting_y_min
    plotting_x_min = plotting_x_min - x_range * x_bord
    plotting_x_max = plotting_x_max + x_range * x_bord
    plotting_y_min = plotting_y_min - y_range * y_bord
    plotting_y_max = plotting_y_max + y_range * y_bord

    if make_plots:
        for i, (fly, ax) in enumerate(zip(fly_nums_in_order, axes_to_set_limits)):
            ax.set_xlim([plotting_x_min, plotting_x_max])
            ax.set_ylim([plotting_y_min, plotting_y_max])
            if i != len(fly_nums_in_order) - 1:
                ax.axis('off')
            else:
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.spines['left'].set_visible(False)
                # TODO make the bottom frame a little further away
                #print 'xticks:', ax.get_xticks()
                ax.set_yticks([])
                # TODO why was this not working?
                #ax.tick_params(axis='x', direction='out')

    if save_plots:
        # TODO flag to output all figs in current dir? (as well?) symlink?
        if title == '':
            fig.savefig('traces.' + plot_format)

        else:
            plt.suptitle(title)
            fig.savefig(title.replace(' ', '_') + '_traces.' + plot_format)

    if (not show_plots) or only_show_interactive:
        plt.close('all')

    # TODO maybe have this function return the results of the loop above, 
    # optionally making plots of traces?
    # how best to break it up?

    if make_plots:
        if want_time_spent:
            # TODO maybe deal with plot format inside function?
            if title == '':
                filename = 'time_spent.' + plot_format
            else:
                filename = title.replace(' ', '_') + '_time_spent.' + plot_format

            plot_metric_change(fractions_reinforced_pre, fractions_reinforced_post, \
                title='Conditioned change in time spent', ylabel='Proportion of test ' + \
                'spent in shocked odor', fly2meta=fly2meta, \
                fly_nums_in_order=fly_nums_in_order, filename=filename)

        if want_decision_bias:
            # TODO factor?
            if title == '':
                filename = 'decision_bias.' + plot_format
            else:
                filename = title.replace(' ', '_') + '_decision_bias.' + plot_format

            # TODO does it currently try to plot anything with only one point for the good trials?
            # should filter those as well if so
            plot_metric_change(decision_biases_pre, decision_biases_post, \
                title='Conditioned change in decision bias', ylabel='Decision bias', \
                fly2meta=fly2meta, fly_nums_in_order=fly_nums_in_order, \
                filename=filename, allow_negative=True)
        # TODO also plot their differences for various groups as swarm plots? print?

    return df

# TODO it seems that running analysis 1 (2?) times after initial scoring, empty plots are gone
# but first 1 (2?) times have some empty plots (should be no_fly) why?
good_fly2data = dict()
for k, v in fly2data.items():
    stamp = split(fly2meta[k]['dir'])[-1]

    if not stamp in bad:
        good_fly2data[k] = v
    elif not fly2meta[k]['n'] in bad[stamp]:
        good_fly2data[k] = v

df = analyze_group(good_fly2data)

formatter = PluralFormatter()

odor_lines = []
for o in all_odors:
    curr_df = df[df['shocked_odor'] == o[0]]
    # TODO how to not need to input positions / kwarg names w/ custom formatter?
    odor_lines.append(formatter.format('{0} good trace{0(s)} with {1} as the ' + \
        'reinforced odor.', len(curr_df), o[0]))
    # TODO handle odor better in filename

    if want_time_spent:
        plot_metric_change(curr_df['fraction_reinforced_pre'], curr_df['fraction_reinforced_post'], \
            title='Conditioned change in preference, ' + o[0] + ' reinforced', \
            ylabel='Proportion of test spent in shocked odor', exps=curr_df['experiment'], \
            rois=curr_df['roi'], filename=o[0] + '_time_spent.' + plot_format)

    if want_decision_bias:
        plot_metric_change(curr_df['decision_bias_pre'], curr_df['decision_bias_post'], \
            title='Conditioned change in decision bias, ' + o[0] + ' reinforced', \
            ylabel='Decision bias', exps=curr_df['experiment'], \
            rois=curr_df['roi'], filename=o[0] + '_decision_bias.' + \
            plot_format, allow_negative=True)

reason2formatstr = {'never_active': '{0} fl{0(y,ies)} were never active',
                    'inactive_after_shock': '{0} fl{0(y,ies)} became inactive after a shock',
                    'no_sample_either_test': '{0} fl{0(y,ies)} did not come close enough' + \
                        ' to sampling one odor during a test',
                    'no_receive_shock': '{0} fl{0(y,ies)} did not appear to receive a shock', \
                    'tracker_artifacts': '{0} trajector{0(y,ies)} appeared to have tracking artifacts'}

lines = []
rois_without_flies = 0
for reason, reject_dict in rejects.items():
    if reason == 'good' or reason == 'suspicious' or reject_dict is None:
        continue

    bad_fly2data = {k: v for k, v in fly2data.items() \
        if split(fly2meta[k]['dir'])[-1] in reject_dict and \
        fly2meta[k]['n'] in reject_dict[split(fly2meta[k]['dir'])[-1]]}

    if reason == 'no_fly':
        if verbose:
            print len(bad_fly2data), 'rois marked as not having a fly in them. not analyzing them.'
        rois_without_flies = len(bad_fly2data)
        continue

    if reason in reason2formatstr:
        lines.append(formatter.format(reason2formatstr[reason], len(bad_fly2data)))

    analyze_group(bad_fly2data, title=reason.replace('_', ' '))

if print_version:
    import git
    choice_path = os.path.realpath(__file__)
    repo = git.Repo(choice_path, search_parent_directories=True)
    current_hash = repo.head.object.hexsha
    repo_url = 'https://github.com/tom-f-oconnell/choice'
    diff = repo.index.diff(None, create_patch=True)
    exactly = 'exactly ' if len(diff) == 0 else ''
    print 'Generated with {} @ {}{}\n'.format(repo_url, exactly, current_hash)

# TODO format this for evernote & upload
total_flies = len(fly2data) - rois_without_flies
print 'Good flies:', str(len(good_fly2data)) + '/' + str(total_flies)
print ''
for line in odor_lines:
    print line
print ''
for line in lines:
    print line
print ''
if want_time_spent:
    print 'Mean difference in time spent in shocked odor:', \
        (df['fraction_reinforced_pre'] - df['fraction_reinforced_post']).mean()
    print 'Median difference in time spent in shocked odor:', \
        (df['fraction_reinforced_pre'] - df['fraction_reinforced_post']).median()
    print ''

if want_decision_bias:
    print 'Mean decision bias difference:', \
        (df['decision_bias_pre'] - df['decision_bias_post']).mean()
    print 'Median decision bias difference:', \
        (df['decision_bias_pre'] - df['decision_bias_post']).median()
    print ''

print 'Experiments represented by each label:'
label2experiment = {v: k for k, v in experiment2label.items()}
assert len(label2experiment) == len(experiment2label)
sorted_labels = sorted(label2experiment.keys())
for k in sorted_labels:
    print k, '-', label2experiment[k]
